{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s-quwucGagW"
      },
      "source": [
        "# **Aperfeiçoamento de Habilidades**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AoQ_TNO1di9"
      },
      "source": [
        "# **IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpbEBf_1oCkl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import getpass\n",
        "import socket\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import jellyfish\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgCc3gXybsA"
      },
      "source": [
        "# **DOWNLOAD, INSTALL AND SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LIB = f\"git clone https://github.com/joseaugustoduarte/linkageColabEnv.git\"\n",
        "if os.system(LIB) != 0: print(f'Error: {LIB}')\n",
        "sys.path.append('/content/linkageColabEnv/')\n",
        "from main import start\n",
        "\n",
        "spark, sc = start()\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import Window\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "XGHhWrrQNccG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4041YVEbUYn"
      },
      "source": [
        "# **FUNÇÕES ÚTEIS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry9FtOYPa93Z"
      },
      "source": [
        "# **PRÉ-PROCESSAMENTO**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploração**"
      ],
      "metadata": {
        "id": "QcZhAmvxPqxt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hJMKNlai7VQ"
      },
      "source": [
        "## **Conversão**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-Y9GnVsxy4k"
      },
      "source": [
        "##### **Validação da Conversão**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH8i8wTebVUO"
      },
      "source": [
        "## **Padronização**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF1Kfvr7bVKP"
      },
      "source": [
        "#### **Criação de ID**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DG9yVm_xU10"
      },
      "source": [
        "##### **Validação da Criação de ID**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Padronização**"
      ],
      "metadata": {
        "id": "IWGKHyGN5LpJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RIws734bVrn"
      },
      "source": [
        "##### **Validação da Padronização**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "242IX6GjbVsl"
      },
      "source": [
        "## **Limpeza de Nomes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Dwz_kczCET"
      },
      "source": [
        "##### **Validação da Limpeza de Nomes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvtR1urtwM4y"
      },
      "outputs": [],
      "source": [
        "# def remove_special_char(texto):\n",
        "#     texto = str(texto)\n",
        "#     texto = unidecode(texto)\n",
        "#     return texto\n",
        "# # udf_remove_special_char = F.udf(lambda texto: remove_special_char(texto), StringType())\n",
        "# udf_remove_special_char = F.udf(remove_special_char, StringType())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFldrHsTy3oo"
      },
      "source": [
        "# **EXTRAÇÃO DE VARIÁVEIS PARA LINKAGE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al46QilfKHhe"
      },
      "source": [
        "# **INDEXAÇÃO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6KXZuTBWgRm"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch, helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgEeoEZLDS8R"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9vU-XL5OZUt"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = '/content/linkage_database/indexing_base_select_150k.csv'\n",
        "index = 'base_150k'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f1BESUzguXN"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(BASE_PATH, header=True, multiLine=True)\n",
        "completude(df)\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8vRXC59_Om9"
      },
      "outputs": [],
      "source": [
        "df.show(3, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04eh7QzoCbPj"
      },
      "outputs": [],
      "source": [
        "h = {\n",
        "    'seq':0,\n",
        "    'name':1,\n",
        "    'mothername':4,\n",
        "    'dtbirth':2,\n",
        "    'sex':3,\n",
        "    'municres':5,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pGKrvoziSsH"
      },
      "outputs": [],
      "source": [
        "es = Elasticsearch('http://localhost:9200/',request_timeout=300, max_retries=15, retry_on_timeout=True)\n",
        "print(f'Info Elastic: {es}\\n{es.info()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb6s0zXNCbR9"
      },
      "outputs": [],
      "source": [
        "bulksize = 15*1000*1000\n",
        "\n",
        "f = open(BASE_PATH, 'r')\n",
        "data  = list()\n",
        "header = True\n",
        "arq = f.readlines()\n",
        "for l in tqdm(arq):\n",
        "#####\n",
        "    if header:\n",
        "        header = False\n",
        "        continue\n",
        "    l = l.replace('\\n', '').split(',')\n",
        "    seq = l[h['seq']].strip()\n",
        "    name = l[h['name']].strip()\n",
        "    mothername = l[h['mothername']].strip()\n",
        "    dtbirth = l[h['dtbirth']].strip().replace('-', '')\n",
        "    sex = l[h['sex']].strip()\n",
        "    municres = l[h['municres']].strip()[:6]\n",
        "\n",
        "    content = {\n",
        "        '_index':index,\n",
        "        '_type':'pessoa',\n",
        "        '_id':str(seq),\n",
        "        '_source':{\n",
        "            'name':str(name),\n",
        "            'mothername':str(mothername),\n",
        "            'dtbirth':str(dtbirth),\n",
        "            'sex':str(sex),\n",
        "            'municres':str(municres),\n",
        "        }\n",
        "    }\n",
        "    data.append(content)\n",
        "\n",
        "    # commit after bulksize is reached\n",
        "    if sys.getsizeof(data)*10 > bulksize:\n",
        "        print('entrei no IFF')\n",
        "        force = True\n",
        "        while(force):\n",
        "            print('entrei no while')\n",
        "            try:\n",
        "                print('entrei no try')\n",
        "                helpers.bulk(es, data)\n",
        "                force = False\n",
        "            except:\n",
        "                print('entrei no except')\n",
        "                continue\n",
        "        # clean data\n",
        "        data = list()\n",
        "\n",
        "helpers.bulk(es, data)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj2QK84oCbUe"
      },
      "outputs": [],
      "source": [
        "es.count(index=index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76zKSLw6x2A_"
      },
      "outputs": [],
      "source": [
        "es.transport.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouqP3OD6N9Px"
      },
      "source": [
        "# **LINKAGE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNse8OglGE1i"
      },
      "outputs": [],
      "source": [
        "linkage_name = 'linkage_base_50k_x_base_150k'\n",
        "\n",
        "source_base = '/content/linkage_database/search_base_clean_select_50k.csv'\n",
        "\n",
        "target_base = f\"/content/{linkage_name}/01_linkage_standard/\"\n",
        "\n",
        "if not os.path.exists(target_base):\n",
        "  os.makedirs(target_base)\n",
        "\n",
        "index = \"base_150k\"\n",
        "\n",
        "indexedBaseHeader = \"150k\"\n",
        "\n",
        "sourceBaseHeader = \"50k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itS2nPpKN7TH"
      },
      "outputs": [],
      "source": [
        "linkage = spark.read.csv(source_base, header=True, sep=\",\", multiLine=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fz6lk-6N7Vj"
      },
      "outputs": [],
      "source": [
        "linkage.show(3, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55ugVxaXN7YE"
      },
      "outputs": [],
      "source": [
        "linkage.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRpnVo47ENMw"
      },
      "outputs": [],
      "source": [
        "h = {\n",
        "    'seq':0,\n",
        "    'name':1,\n",
        "    'mothername':2,\n",
        "    'dtbirth':5,\n",
        "    'sex':3,\n",
        "    'municres':4\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUaq4ZgpxpRs"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch, helpers\n",
        "es = Elasticsearch('http://localhost:9200/',request_timeout=300, max_retries=15, retry_on_timeout=True)\n",
        "print(f'Info Elastic: {es}\\n{es.info()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5xD1vqRN7av"
      },
      "outputs": [],
      "source": [
        "dic_bases = []\n",
        "\n",
        "with open(source_base, 'r') as base:\n",
        "    header = True\n",
        "    c = 0\n",
        "\n",
        "    for l in tqdm(base):\n",
        "\n",
        "        # If csv contains header as first line, skip it\n",
        "        if header or 'id_' in l:\n",
        "            header = False\n",
        "            continue\n",
        "        c += 1\n",
        "\n",
        "        # Split csv line\n",
        "        l = l.replace('\\n', '').split(',')\n",
        "        # Get each char\n",
        "        seq = l[h['seq']].strip()\n",
        "        name = l[h['name']].strip()\n",
        "        mothername = l[h['mothername']].strip()\n",
        "        dtbirth = l[h['dtbirth']].strip().replace('-', '')\n",
        "        sex = l[h['sex']].strip()\n",
        "        municres = l[h['municres']].strip()[:6]\n",
        "\n",
        "        # If all fields are blanks, then don't add the register, add it otherwise.\n",
        "        if not (name == '' and mothername == '' and dtbirth == '' and sex == '' and municres == ''):\n",
        "            content = {\n",
        "                'seq': str(seq),\n",
        "                'name': str(name),\n",
        "                'mothername': str(mothername),\n",
        "                'dtbirth': str(dtbirth),\n",
        "                'sex': str(sex),\n",
        "                'municres': str(municres)\n",
        "            }\n",
        "            dic_bases.append(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bco9pEg2N7dW"
      },
      "outputs": [],
      "source": [
        "# Exact search on elastic search function\n",
        "def searchExactPerson(name, mothername, municres, dtbirth, sex, startId=0):\n",
        "    global es\n",
        "    content = {\n",
        "        'size': 30,\n",
        "        'query': {\n",
        "            'bool': {\n",
        "                'must': [\n",
        "                    {'match_phrase': {'name': '\"' + name + '\"'}},\n",
        "                    {'match_phrase': {'mothername': '\"' + mothername + '\"'}},\n",
        "                    {'match': {'municres': municres}},\n",
        "                    {'match': {'dtbirth': dtbirth}},\n",
        "                    {'match': {'sex': sex}}\n",
        "                ],\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    force = True\n",
        "    while force:\n",
        "        try:\n",
        "            res = es.search(index=index, body=content)\n",
        "            force = False\n",
        "        except:\n",
        "            pass\n",
        "    return res['hits']['hits']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHg0mCwISO83"
      },
      "outputs": [],
      "source": [
        "# Fuzzy search on elastic search function\n",
        "def searchFuzzyPerson(name, mothername, municres, dtbirth, sex, startId=0):\n",
        "    global es\n",
        "    content = {\n",
        "        'size': 100,\n",
        "        'query': {\n",
        "            'bool': {\n",
        "                'should': [\n",
        "                    {'match': {'name': {'query': name, 'fuzziness': 'AUTO', 'operator': 'or', 'boost': '2'}}},\n",
        "                    {'match': {'mothername': {'query': mothername, 'fuzziness': 'AUTO', 'operator': 'or', 'boost': '1.5'}}},\n",
        "                    {'match': {'dtbirth': {'query': dtbirth, 'fuzziness': 'AUTO', 'operator': 'or'}}},\n",
        "                    {'match': {'municres': {'query': municres, 'fuzziness': 'AUTO', 'operator': 'or', 'boost': '0.5'}}},\n",
        "                    {'match': {'sex': {'query': sex, 'fuzziness': 'AUTO', 'operator': 'or'}}}\n",
        "                ],\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    force = True\n",
        "    while force:\n",
        "        try:\n",
        "            res = es.search(index=index, body=content)\n",
        "            force = False\n",
        "        except:\n",
        "            pass\n",
        "    return res['hits']['hits']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6l05FptN7gL"
      },
      "outputs": [],
      "source": [
        "def findBestCandidate(candidates, person):\n",
        "    if candidates:\n",
        "        scores = []\n",
        "        for candidate in candidates:\n",
        "            score = compare(candidate['_source'], person)\n",
        "            scores.append((score, candidate))\n",
        "        scores.sort(key=lambda x: x[0], reverse=True)\n",
        "        bestCandidate = scores[0][1]\n",
        "        bestScore = scores[0][0]\n",
        "        bestCandidate['_source']['score'] = bestScore\n",
        "        return bestCandidate\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8mFSbdjN7i-"
      },
      "outputs": [],
      "source": [
        "def compare(candidate, source):\n",
        "    # Weights\n",
        "    name_w = 1.0\n",
        "    mothername_w = 1.0\n",
        "    state_w = 0.04\n",
        "    municres_w = 0.08\n",
        "    dtbirth_w = 1.0\n",
        "    sex_w = 0.5\n",
        "\n",
        "    # Max score\n",
        "    score_max = name_w + mothername_w + state_w + municres_w + dtbirth_w + sex_w\n",
        "\n",
        "    # Initialize scores and penaly\n",
        "    score_name, score_mothername, score_birth, score_municres, score_sex, penalty = 0, 0, 0, 0, 0, 0\n",
        "\n",
        "    # Compare individuals name with jaro distance\n",
        "    score_name = jellyfish.jaro_winkler_similarity(candidate['name'], source['name']) * name_w\n",
        "\n",
        "    # Compare individuals mothername with jaro distance\n",
        "    score_mothername = jellyfish.jaro_winkler_similarity(candidate['mothername'], source['mothername']) * mothername_w\n",
        "\n",
        "    # Compare individuals birthdate\n",
        "    if candidate['dtbirth'] == '' or source['dtbirth'] == '':\n",
        "        score_max -= dtbirth_w\n",
        "        penalty = penalty + 0.05\n",
        "    else:\n",
        "        score_birth = (1.0 - float(jellyfish.hamming_distance(candidate['dtbirth'], source['dtbirth'])) / max(len(candidate['dtbirth']), len(source['dtbirth'])))\n",
        "\n",
        "    # Compare individuals sex\n",
        "    if candidate['sex'] in ['', '88', '99'] or source['sex'] in ['', '88', '99']:\n",
        "        score_max -= sex_w\n",
        "        penalty = penalty + 0.01\n",
        "    elif candidate['sex'] == source['sex']:\n",
        "        score_sex = sex_w\n",
        "\n",
        "   # Compare municipality\n",
        "    if candidate['municres'] == '' or source['municres'] == '':\n",
        "        score_max -= (state_w+municres_w)\n",
        "        penalty += 0.02\n",
        "    else:\n",
        "        if candidate['municres'][0:2] == source['municres'][0:2]:\n",
        "            score_municres += state_w\n",
        "            # City would be the same only if state is the same\n",
        "            if candidate['municres'][2:6] == source['municres'][2:6]:\n",
        "                score_municres += municres_w\n",
        "\n",
        "    # Calculate score\n",
        "    score = ((score_name + score_mothername + score_birth + score_sex + score_municres) / score_max) - penalty\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRPW157-SStO"
      },
      "outputs": [],
      "source": [
        "def cidacsrl(source):\n",
        "    result = ''\n",
        "    # Perform exact search\n",
        "    candidates = searchExactPerson(name=source['name'], mothername=source['mothername'], municres=source['municres'], dtbirth=source['dtbirth'], sex=source['sex'])\n",
        "    if candidates:\n",
        "        bestCandidate = findBestCandidate(candidates, source)\n",
        "        # If score > 0.95 treat candidate as exact match\n",
        "        if bestCandidate['_source']['score'] >= .95:\n",
        "            score = str(bestCandidate['_source']['score'])\n",
        "            fields = [bestCandidate['_id'], source['seq'], bestCandidate['_source']['name'], source['name'], bestCandidate['_source']['mothername'], source['mothername'], bestCandidate['_source']['municres'], source['municres'], bestCandidate['_source']['dtbirth'], source['dtbirth'], bestCandidate['_source']['sex'], source['sex'], score]\n",
        "            result = ','.join(fields) + '\\n'\n",
        "    # If no candidate is selected, perform fuzzy search\n",
        "    if result == '':\n",
        "        candidates = searchFuzzyPerson(name=source['name'], mothername=source['mothername'], municres=source['municres'], dtbirth=source['dtbirth'], sex=source['sex'])\n",
        "        bestCandidate = findBestCandidate(candidates, source)\n",
        "        if bestCandidate:\n",
        "            score = str(bestCandidate['_source']['score'])\n",
        "            fields = [bestCandidate['_id'], source['seq'], bestCandidate['_source']['name'], source['name'], bestCandidate['_source']['mothername'], source['mothername'], bestCandidate['_source']['municres'], source['municres'], bestCandidate['_source']['dtbirth'], source['dtbirth'], bestCandidate['_source']['sex'], source['sex'], score]\n",
        "            result = ','.join(fields) + '\\n'\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8ye77tQSWIP"
      },
      "outputs": [],
      "source": [
        "# Build datamart header\n",
        "headerFields = ['seq', 'name', 'mothername', 'municres', 'dtbirth', 'sex']\n",
        "larger = [x + '_' + indexedBaseHeader for x in headerFields]\n",
        "smaller = [x + '_' + sourceBaseHeader for x in headerFields]\n",
        "l = []\n",
        "for i in range(len(larger)):\n",
        "    l.append(larger[i])\n",
        "    l.append(smaller[i])\n",
        "l.append('score')\n",
        "header = ','.join(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFxQ8JwoSYVE"
      },
      "outputs": [],
      "source": [
        "def writeLinkageLocal(target_file, header, result):\n",
        "  f = open(target_file, 'w')\n",
        "  f.write((header + '\\n'))\n",
        "  for line in tqdm(result):\n",
        "      f.write(line)\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDWizUIZSduv"
      },
      "outputs": [],
      "source": [
        "from multiprocessing.dummy import Pool as ThreadPool\n",
        "\n",
        "targetFile = f\"{target_base}{linkage_name}.csv\"\n",
        "\n",
        "marker = time.time()\n",
        "marker_log = datetime.datetime.now()\n",
        "num_tasks = len(dic_bases)\n",
        "result = []\n",
        "c, elapsed_time = 0, 0\n",
        "with ThreadPool() as pool:\n",
        "  for j, x in enumerate(pool.imap_unordered(cidacsrl, dic_bases)):\n",
        "      result.append(x)\n",
        "      c += 1\n",
        "      elapsed_time = time.time() - marker\n",
        "      done = len(result)/num_tasks*100\n",
        "\n",
        "      estimated = str(datetime.timedelta(seconds = (num_tasks-c) * (elapsed_time/c)))\n",
        "      sys.stderr.write(f\"\\rDone: {done:.2f}% | Records: {len(result)}/{len(dic_bases)} | Estimated time: {estimated} | Elapsed time: {str(datetime.timedelta(seconds=time.time()-marker))}\")\n",
        "\n",
        "print('\\nSalvando linkage em:\\n', targetFile)\n",
        "time_linkage=datetime.datetime.now()-marker_log\n",
        "\n",
        "# Linkage writing function, if there is a failure the file will be saved in the temporary directory\n",
        "writeLinkageLocal(target_file=targetFile, header=header, result=result)\n",
        "\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-EeE9UxcVwF"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/linkage_base_50k_x_base_150k/01_linkage_standard/linkage_base_50k_x_base_150k.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u8pEUk_2W6y"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-nluCFYVBqf"
      },
      "outputs": [],
      "source": [
        "es.transport.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I46DGgXHNTIl"
      },
      "source": [
        "# **VALIDAÇÃO DO LINKAGE**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/linkage_database/linkage_base_50k_x_base_150k.csv'"
      ],
      "metadata": {
        "id": "cHq7_ksrUwH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yUWj99vTlL4"
      },
      "outputs": [],
      "source": [
        "linkage = spark.read.csv(PATH, header=True, sep=\",\", multiLine=True)\\\n",
        "    .withColumn('score', F.col('score').cast(DoubleType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GIUu6lSCXyu"
      },
      "outputs": [],
      "source": [
        "linkage.show(10, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqavCveWTlTF"
      },
      "outputs": [],
      "source": [
        "LINKAGE_COUNT = linkage.count()\n",
        "print(f\"Records: {LINKAGE_COUNT} | Variables: {len(linkage.columns)}\\n\")\n",
        "linkage.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63HthEPYTlZx"
      },
      "outputs": [],
      "source": [
        "print(f\"Records with scores above 0.92: {(linkage.filter(linkage.score >= 0.92).count() / LINKAGE_COUNT * 100):.2f}%\")\n",
        "linkage.groupBy(F.substring('score', 1, 3).alias('faixa_score')).count()\\\n",
        "            .withColumn('%', F.round(F.col('count') / LINKAGE_COUNT * 100, 3))\\\n",
        "            .orderBy(F.col('faixa_score').desc()).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iPlwezDTlcc"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "f, ax = plt.subplots(figsize=(24,8))\n",
        "score_pd = linkage.select('score').sample(False, 0.99, 42).toPandas().apply(pd.to_numeric)\n",
        "score_pd.plot(kind='hist',ax=ax,bins=70,fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBkTPyF9TlfE"
      },
      "outputs": [],
      "source": [
        "inconsistent_scores = linkage.filter((F.col('score') > 1) | (F.col('score') < 0))\n",
        "\n",
        "inconsistent_scores.show(100, False)\n",
        "\n",
        "inconsistent_scores.groupBy('score').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FjCewbPWlY-"
      },
      "outputs": [],
      "source": [
        "name_columns = [col for col in linkage.columns if col.startswith('name')]\n",
        "mothername_columns = [col for col in linkage.columns if col.startswith('mothername')]\n",
        "dtbirth_columns = [col for col in linkage.columns if col.startswith('dtbirth')]\n",
        "sex_columns = [col for col in linkage.columns if col.startswith('sex')]\n",
        "codmunres_columns = [col for col in linkage.columns if col.startswith('municres')]\n",
        "\n",
        "inconsistents_scores = linkage.filter(\n",
        "    (F.col(name_columns[0]) == F.col(name_columns[1])) &\n",
        "    (F.col(mothername_columns[0]) == F.col(mothername_columns[1])) &\n",
        "    (F.col(dtbirth_columns[0]) == F.col(dtbirth_columns[1])) &\n",
        "    (F.col(sex_columns[0]) == F.col(sex_columns[1])) &\n",
        "    (F.col(codmunres_columns[0]) == F.col(codmunres_columns[1])) &\n",
        "    (F.col('score') != 1)\n",
        ")\n",
        "\n",
        "INCONSISTENTS_SCORES_COUNT = inconsistents_scores.count()\n",
        "print(f\"Registros com todos atributos iguais, porém com score diferente de 1: {INCONSISTENTS_SCORES_COUNT}\")\n",
        "if INCONSISTENTS_SCORES_COUNT > 0: cidacs.show(inconsistents_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBb40RsQXFPx"
      },
      "outputs": [],
      "source": [
        "inconsistents_scores = linkage.filter(\n",
        "    (\n",
        "        (F.col(name_columns[0]) != F.col(name_columns[1])) |\n",
        "        (F.col(mothername_columns[0]) != F.col(mothername_columns[1])) |\n",
        "        (F.col(dtbirth_columns[0]) != F.col(dtbirth_columns[1])) |\n",
        "        (F.col(sex_columns[0]) != F.col(sex_columns[1])) |\n",
        "        (F.col(codmunres_columns[0]) != F.col(codmunres_columns[1]))\n",
        "    ) & (F.col('score') == 1)\n",
        ")\n",
        "\n",
        "INCONSISTENTS_SCORES_COUNT = inconsistents_scores.count()\n",
        "print(f\"Registros com atributos diferentes, porém score igual a 1: {INCONSISTENTS_SCORES_COUNT}\")\n",
        "if INCONSISTENTS_SCORES_COUNT > 0: cidacs.show(inconsistents_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4K4UmBJNgeR"
      },
      "source": [
        "# **DATAMART COM LINKADOS**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-AoQ_TNO1di9",
        "upgCc3gXybsA",
        "DF1Kfvr7bVKP",
        "IWGKHyGN5LpJ",
        "89Dwz_kczCET",
        "Al46QilfKHhe",
        "ouqP3OD6N9Px",
        "I46DGgXHNTIl"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}